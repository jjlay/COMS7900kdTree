\documentclass{article}

\usepackage[a4paper,margin=1.15in,footskip=0.25in]{geometry}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{textpos}
\usepackage{textcomp}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{algorithmic}
\usepackage{verbatim}
\usepackage{textcomp}
\usepackage{varwidth}
\usepackage[linesnumbered,ruled]{algorithm2e}

% Theorem
\newtheorem{theorem}{Theorem}

% lists
\usepackage{outlines}
\usepackage{enumitem}
\newenvironment{tight_enum}{
\begin{enumerate}[label=\alph*.]
\setlength{\itemsep}{0pt}
\setlength{\parskip}{0pt}
}{\end{enumerate}}

% \subsubsubsection{}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\newcommand\simpleparagraph[1]{%
  \stepcounter{paragraph}\paragraph*{\theparagraph\quad{}#1}}

\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{mdframed}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

% \usepackage{courier}
\lstset{%frame=tb,
language=C++,
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
basicstyle={\small\ttfamily},
numbers=none,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=3
}

%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%
%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%
%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%

\begin{document}

\title{Parallel Orthogonal Recursive Bisection}
\author{Team Metropolis: \\
		Jamshid 'James' Farzidayeri, JJ Lay, and Graham West}
\date{COMS 7900, Capstone}

\maketitle

\begin{abstract}
In our first project, we implemented a parallel sorting algorithm which utilized a local gradient-type optimization search to equalize the amount of data across different compute nodes in order to achieve maximum efficiency. In this project, we applied this algorithm to the problem of parallel orthogonal recursive bisection (ORB), i.e., the construction of $k$-d trees. In order to do this, we had to heavily modify the sorting algorithm in several ways, including 1) turning it into a callable function, 2) letting the rank 0 head node perform work while still managing the tasks, 3) incorporating the use of different MPI communicators, and 4) altering the adaptive binning technique for better convergence.

In this paper, we will discuss how our $k$-d tree algorithm works, how we solved the various issues plaguing parallel sort (mentioned above), and how we tested and validated our work. We conclude with a discussion of the major difficulties in completing this project and how these difficulties could be minimized in the future.
\end{abstract}


\tableofcontents


%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Introduction}

\subsection{Workflow}
How we went about the project...

new GitHub repo

EXTREME CODING FTW: catch errors quickly, no merge conflicts, everyone writes/knows all the code

We all wrote prototypes in several languages before attempting the full C++ parallel version. We chose to follow the format Graham used in his MATLAB implementation.

\subsection{Variables and conventions}
%%% NOTE %%%
%%% NOTE %%%
% 1) be consistent with the indices:
% 2) say head node (not master node)
% 3) say worker (not node) whenever possible
%%% NOTE %%%
%%% NOTE %%%

Here we provide a helpful list of conventions, notations, and variable names used throughout this paper.

\begin{mdframed}[backgroundcolor=blue!20]
	Counts:
	\setlength\itemsep{0.1pt}
	\setlength\parskip{0.1pt}
	\begin{itemize}
		\setlength\itemsep{0.1pt}
		\setlength\parskip{0.1pt}
		\item $N$: number of nodes
		\item $M$: max number of allowed time steps
		\item $L$: number of lines to read per file
		\item $L_w$: number of lines on the $w$th worker
		\item $D$: total number of lines/data points
	\end{itemize}
\end{mdframed}

\begin{mdframed}[backgroundcolor=blue!20]
	Indices:
	\setlength\itemsep{0.1pt}
	\setlength\parskip{0.1pt}
	\begin{itemize}
		\setlength\itemsep{0.1pt}
		\setlength\parskip{0.1pt}
		\item $m = 0, \cdots, M$ is the time step of the bin adaptation scheme (likely less than $M$)
		\item $n = 0, \cdots, W$ spans the nodes
		\item $i = 0, \cdots, N$ spans the bin edges/indices
		\item $j = 0, \cdots, N-1$ spans the bin counts (this will occasionally subscript binI/E as well)
		\item $\ell_w = 0, \cdots, L_n-1$ spans the lines on the $n$-th node
		\item $k = 0, \cdots, 3$ is the data column being sorted
	\end{itemize}
\end{mdframed}

\begin{mdframed}[backgroundcolor=blue!20]
	Variables:
	\setlength\itemsep{0.1pt}
	\setlength\parskip{0.1pt}
	\begin{itemize}
		\setlength\itemsep{0.1pt}
		\setlength\parskip{0.1pt}
		\item $\textrm{data}^n_{4\ell+k}$: data point on $\ell$th line and $k$th column on the $n$-th node
		\item ${E}^m_j$: bin edges (0 indexed) at time step $m$
		\item ${I}^{n,m}_j$: bin indices on node $n$
		\item ${C}^{n,m}_j$: bin counts on node $n$ at time step $m$
		\item ${C}^m_j$: total bin counts on head node (sum of node C's) at time step $m$
	\end{itemize}
\end{mdframed}


%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Implementation}
Here we discuss our implementation of the code

\subsection{Altered parallel sorting}


\subsubsection{\texttt{parallelSort}}

\paragraph{Conversion to function}

\paragraph{Making rank 0 do work}

\paragraph{Using different communicators}



\subsubsection{\texttt{adaptBins}}
Although our original adaptive binning scheme performed well, we wanted something which could do even better since $k$-d trees require many parallelSort calls. As a review, here is our original method:
\begin{equation}
	\begin{split}
		\Delta C & = 2.0 ( C^{m}_{i+1} - C^{m}_i ) / ( C^{m}_{i+1} + C^{m}_i ) \\
		\Delta E & = E^m_{i+1} - E^m_i \\
		E^{m+1}_i & = E^m_i + \alpha \Delta C \Delta E
	\end{split}
\end{equation}
% added scale factor
where $C$ are the bin counts, $E$ are the bin edges, and $\alpha < 0.5$. This method will occasionally devolve into oscillatory behavior and not converge to the correct value. To combat this in the $k$-d tree project, we added a scale factor $S$ which decreases over time:
\begin{equation}
	\begin{split}
		S & = 1 - (1 - 0.1) (1 - \textrm{exp}(-0.03 m) \\
		E^{m+1}_i & = E^m_i + \alpha S \Delta C \Delta E
	\end{split}
\end{equation}

Since this method is local, it converges slowly at bin edges far away from high-density clusters. As such, we attempted to replace this method with a global method which uses linear interpolation to estimate where the bins would be evenly distributed. Define the function $\hat C(x)$ as the linear approximation of the cumulative count distribution of the data points (so that it normalizes to the number of data points, not unity). Then,
\begin{equation}
		\hat C(x) = \hat C(E^m_{i'}) + C^m_{i'} \dfrac{x - E^m_{i'}}{E^m_{{i'}+1} - E^m_{i'}} = (i+1) \dfrac{D}{N}
\end{equation}
where $i'$ is the maximum index such that $\hat C(E_{i'}) < (i+1) \dfrac{D}{N}$ (note that $i'$ and $i$ are distinct integers). The right equality implies that we should solve for the value of $x$ such that it holds. This $x$ value will be the new $i$-th bin edge, $E^{m+1}_i$. Therefore,
\begin{equation}
		E^{m+1}_i = E^m_{i'} + \bigg( (i+1) \dfrac{D}{N} - C(E^m_{i'}) \bigg) (E^m_{{i'}+1} - E^m_{i'}) / C^m_{i'}
\end{equation}

We discovered that this adaptation technique performs very will in initial steps of adaptation, but is prone to oscillations near clusters of points. Now, since each of the two methods perform better and worse in different contexts, are solution was to simply alternate between at each step. This solved all of our convergence issues in testing. (Note that we still use the same binary search-based binning technique and stopping criterion from the previous project.)


\subsection{$K$-d tree}
Used a Tree struct...

% JJ, talk about the Tree struct and what all fields it has

\subsubsection{Building the tree}
General notes on the method...


\paragraph{\texttt{buildTree}}
This function gets the number of compute nodes $q$ available in the current communicator and determines which function to run. If $q>1$, then we can still do a parallel sort with 2 compute nodes, so \texttt{buildTree\_parallel} is entered. If $q=1$, then \texttt{buildTree\_serial} is entered.


\paragraph{\texttt{buildTree\_serial}}
This was the first function written after our initial prototyping phase was completed. It essentially performs a serial version of ORB which can be executed on a single compute node.

% JJ, you wanna write this since you wrote the program?

Upon completion, \texttt{buildTree\_serial} calls itself instead of \texttt{buildTree} since we still have $q=1$.


\paragraph{\texttt{buildTree\_parallel}}
This function performs essentially the same tasks as \texttt{buildTree\_serial}, but utilizing multiple nodes for speedup. Specifically, it takes advantage of \texttt{parallelSort} in order to speed up the partitioning of the data along the longest axis (determine by \texttt{getSortDim}, discussed below). After the data has been sorted, the data is split by placing lower half (w.r.t. the sorted data values) of the compute nodes into a left communicator and the upper half into a right communicator. Each half then calls \texttt{buildTree}.

% Upon completion, \texttt{buildTree\_parallel} has spawned 2 new communicators (a left and a right) each of which has half as many compute nodes as the parent communicator. All of the nodes from each side then call \texttt{buildTree} so that they can perform the $q$ check.


\paragraph{\texttt{getSortDim}}
This function is used by \texttt{buildTree\_parallel} in order to determine which is the longest axis, i.e., the sort dimension. In addition to this, it also fills in the struct for the current tree node with the global min/max in all three dimensions, as well as the center of the bounding box defined by these values.


\subsubsection{Searching the tree}

\paragraph{\texttt{searchTree\_serial}}

\paragraph{\texttt{searchTree\_}PARALLEL???}



%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Testing and Validation}



%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Results}



%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Conclusion}



%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Bibliography}

\end{document}
