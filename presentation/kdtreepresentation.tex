\documentclass{beamer}

\usepackage[utf8]{inputenc}
\usepackage{epstopdf}
\usepackage{textpos}
\usepackage{textcomp}
\usepackage{verbatim}
\usepackage{varwidth}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage[linesnumbered,ruled]{algorithm2e}
\usepackage{graphicx}
\usepackage{listings}
%\usepackage{lipsum}
%\usepackage{dblfloatfix}
%\usepackage{multicol}
%\usepackage[ruled]{algorithm2e}

\lstset{%frame=tb,
language=C++,
aboveskip=3mm,
belowskip=3mm,
showstringspaces=false,
columns=flexible,
basicstyle={\small\ttfamily},
numbers=none,
numberstyle=\tiny\color{gray},
keywordstyle=\color{blue},
commentstyle=\color{dkgreen},
stringstyle=\color{mauve},
breaklines=true,
breakatwhitespace=true,
tabsize=3
}

\usefonttheme[onlymath]{serif}
%\setlength{\columnsep}{5cm}

% table of contents font size
\setbeamerfont{section in toc}{size=\footnotesize}
\setbeamerfont{subsection in toc}{size=\scriptsize}
\setbeamerfont{subsubsection in toc}{size=\scriptsize}

\setbeamertemplate{caption}[numbered]

% standard, good-looking theme
\usetheme{Madrid}

% this should put the outline on the header of each page
% can't make it look right, though
% \usetheme{Darmstadt}



\title[Capstone]{Parallel Orthogonal Recursive Bisection}

\author{Team Metropolis:\\
	James Farzi, JJ Lay, Graham West}
\date{April 19, 2019}



%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%
%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%
%%%%%%%%% BEGIN DOCUMENT %%%%%%%%%

\begin{document}

% get title page 
\frame{\titlepage}

\begin{frame}	
	\frametitle{Outline}
	\tableofcontents
\end{frame}


%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Introduction}

\begin{frame}	
	\begin{Huge}
		\begin{center}
			Introduction
		\end{center}
	\end{Huge}
\end{frame}

\begin{frame}	
    \frametitle{Introduction}
    	
    	Expansion upon previous parallel sorting project
    	
    	\vspace{10pt}
    	
    	\begin{block}{Objectives:}
    		\begin{itemize}
    			\item Given set of data
    			\item Develop parallel orthogonal recursive bisection (ORB) algorithm
    			\item Utilize a $k$-d tree to organize data
    			\item Maximize use of MPI using multiple nodes
    			\item Require both serial/parallel build/search operations
    			\item Search the $k$-d data with a list of points and 3 radii
    		\end{itemize}
    	\end{block}
\end{frame}

\begin{frame}	
    \frametitle{Introduction}
    	SUBLISTSSSSSS
    	\begin{block}{Workflow:}
    		\begin{itemize}
    			\item Used C++ w/ C MPI calls
    			\item Valgrind/gdb for debugging
    			\item Using Git effectively (multiple branches, few merge conflicts)
   			\item Extreme coding if FUN...and powerful
   			\item Prototyping: we each wrote our own, implementation based on Graham's MATLAB code
    		\end{itemize}
    	\end{block}
\end{frame}




%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Implementation}

\begin{frame}	
	\begin{Huge}
		\begin{center}
			Implementation
		\end{center}
	\end{Huge}
\end{frame}

\subsection{\texttt{main}}

\begin{frame}
	\frametitle{\texttt{main}}
	
	Our \texttt{main} was quite simple due to our organization of the project into many levels of functions
	
	\vspace{10pt}
	
	We also were able to use much of the basic initialization and data importing functions from the previous project
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
%		\footnotesize
		\begin{algorithmic}[1]
			\STATE Initialize MPI
			\STATE Set number of files, lines per file to read
			\STATE import the $data$
%			\STATE MPI\_Barrier
			\STATE Initialize $tree$
			\STATE \texttt{buildTree}($data$, $tree$, $comm$, $\cdots$)
%			\STATE MPI\_Barrier
			\STATE Search the tree with \texttt{search501}( $tree$, $\cdots$)
%			\STATE MPI\_Barrier
			\STATE Finalize MPI
		\end{algorithmic}
	\caption{\texttt{main}($\cdots$)}
	\end{algorithm}
		
\end{frame}

\subsection{Importing Data}

\begin{frame}
	\frametitle{Importing Data}
	
    	\begin{block}{Importing the data:}
	    	
    		\texttt{listFiles}($\cdots$)
    		\begin{itemize}
    			\item Fetches a list of data filenames using OS calls (random order)
    		\end{itemize}
    		
    		\texttt{distributeFiles}($\cdots$), \texttt{receiveFiles}($\cdots$)
    		\begin{itemize}
    			\item Isend/Recv the list of filenames
    			\item Round robin distribution of files
    		\end{itemize}
    		
    		\texttt{importFiles}($\cdots$)
    		\begin{itemize}
    			\item Reads the received filenames
    			\item Read a set nFiles and nLinesPerFile
    			\item Returns a 1D array of length 4 $\times$ nFiles $\times$ nLinesPerFile
    			\item nFiles $\ge$ nNodes
    		\end{itemize}
    	\end{block}
		
\end{frame}

\subsection{Tree Structure}

\begin{frame}[fragile]
	\frametitle{Tree Structure}
	
    	\begin{block}{Old tree struct:}
    		\begin{itemize}
    			\item Contained extra debugging fields
    			\item Contained completely unused fields
    			\item Originally used doubles
    			\item tree naming
    		\end{itemize}
    	\end{block}
    
\begin{texttt}
struct Tree \{
	Tree *p;  // Parent
	Tree *l;  // Left child
	Tree *r;  // Right child

	MPI\_Comm parentComm, leftComm, rightComm, thisComm;

	float x1;  // Min x
	float x2;  // Max x
	float y1;  // Min y
	float y2;  // Max y
	float z1;  // Min z
	float z2;  // Max z

	float c[4];  // Center of this tree
	float radius;

	float d[4];  // Data point
\}
\end{texttt}

		
\end{frame}

\begin{frame}
	\frametitle{C Constants}
	
    	\begin{block}{\texttt{definitions.h}:}
	    	A header file containing numerous pre-process identifiers (\texttt{\#define}):
    		\begin{itemize}
    			\item \texttt{\_INDEX\_, \_X\_, \_Y\_, \_Z\_}
    			\item Count limits (adapt bins max iterations, max nLinesPerFile, etc.)
    			\item MPI tags (bin edge, bin count, uniformity, etc.)
    		\end{itemize}
    	\end{block}
		
\end{frame}

\subsubsection{Building the tree}

\begin{frame}
	\frametitle{Building the tree}
	
	To build the tree, we use several functions which perform different aspects/sections of the task
	
	\vspace{10pt}
	
	\begin{block}{Functions:}
		\begin{itemize}
			\item \texttt{buildTree}
			\item \texttt{buildTree\_serial}
			\item \texttt{buildTree\_parallel}
			\item \texttt{getSortDim}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
   \begin{figure}[h!]
   	\centering
      \includegraphics[width=0.9\textwidth]{images/communicators.png}
      \caption{Example of parallel variables using eight nodes}
      \label{fig:communicators}
   \end{figure}
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
	\texttt{buildTree} checks the number of compute nodes in the current communicator and determines whether to call the parallel or serial versions of the code
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
		\begin{algorithmic}[1]
			\STATE $q$ = Size of current communicator
			\IF{ $q > 1$}
				\STATE \texttt{buildTree\_parallel}($data$, $tree$, $comm, \cdots$)
			\ELSE
				\STATE \texttt{buildTree\_serial}($data$, $tree$, $\cdots$)
			\ENDIF
		\end{algorithmic}
	\caption{\texttt{buildTree}($data$, $tree$, $comm, \cdots$)}
	\end{algorithm}
		
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
	\texttt{buildTree\_parallel} performs ORB using a multiple compute nodes
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
		\footnotesize
		\begin{algorithmic}[1]
			\STATE Call \texttt{getSortDim}($\cdots$): calculates $x,y,z$ mins, maxs, ranges, partition center, and returns $sortDim$
			\STATE Sort $data$ over $sortDim$ using \texttt{parallelSort}($data$, $sortDim$, $comm$, $\cdots$ )
			\IF{ $myRank < numNodes/2$ }
				\STATE Create $tree.L$, $commL$
				\STATE \texttt{buildTree\_parallel}( $data$, $tree.L$, $comm, \cdots$ )
			\ELSE
				\STATE Create $tree.R$, $commR$
				\STATE \texttt{buildTree\_parallel}( $data$, $tree.R$, $comm, \cdots$ )
			\ENDIF
		\end{algorithmic}
		\caption{\texttt{buildTree\_parallel}($data$, $tree$, $comm, \cdots$)}
	\end{algorithm}
	
	\vspace{10pt}
	
	It is assumed that $tree.n > 1$ will never occur in \texttt{build/tree\_parallel} since we usually deal with large amounts of data
		
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
	\texttt{buildTree\_serial} performs ORB using a single compute node
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
		\footnotesize
		\begin{algorithmic}[1]
			\IF{ $tree.n >1$}
				\STATE Calculate $x,y,z$ mins, maxs, ranges, and partition center
				\STATE Sort $data$ over $sortDim = \textrm{argmax}( x,y,z \textrm{ ranges})$
				\STATE Split $data$: $dataL, dataR$
				\IF{ $|dataL| > 0$ }
					\STATE Create $tree.L$
					\STATE \texttt{buildTree\_serial}( $dataL$, $tree.L, \cdots$ )
				\ENDIF
				\IF{ $|dataR| > 0$ }
					\STATE Create $tree.R$
					\STATE \texttt{buildTree\_serial}( $dataR$, $tree.R, \cdots$ )
				\ENDIF
			\ELSE
				\STATE Store $data$ (a single point)
			\ENDIF
		\end{algorithmic}
	\caption{\texttt{buildTree\_serial}($data$, $tree, \cdots$)}
	\end{algorithm}
		
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
	\texttt{getSortDim} finds the longest axis and stores several key tree fields
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
%		\footnotesize
		\begin{algorithmic}[1]
			\STATE Each process gets it local $x,y,z$ min and max
			\STATE Rank 0 receives these, determines the global $x,y,z$ min and max, determines the sortDim, and Bcast's all of these values back to the other nodes
			\STATE The global mins/maxs, partition center, and partition radius are stored in $tree$
			\STATE return $sortDim$
		\end{algorithmic}
		\caption{\texttt{getSortDim}($data$, $tree$, $comm, \cdots$)}
	\end{algorithm}
		
\end{frame}


\subsubsection{Searching the tree}

\begin{frame}
	\frametitle{Searching the tree}
	
	\texttt{searchTree\_serial} returns the number of points within a given radius about a given point
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
		\footnotesize
		\begin{algorithmic}[1]
			\STATE $found = 0$
			\STATE $d = \sqrt{ \sum_{i=1}^{3} (point[i] - tree.c[i])^2}$
			\IF{ $d \le rad + tree.rad$ }
				\IF{ $tree.L = NULL$ \&\& $tree.R = NULL$ }
					\STATE return 1
				\ELSE
					\IF{ $tree.L$ != $NULL$ }
						\STATE $found$ += \texttt{searchTree\_serial}($tree.L$, $rad$, $point$)
					\ENDIF
					\IF{ $tree.R$ != $NULL$ }
						\STATE $found$ += \texttt{searchTree\_serial}($tree.R$, $rad$, $point$)
					\ENDIF
				\ENDIF
			\ENDIF
		\end{algorithmic}
		\caption{\texttt{searchTree\_serial}($tree$, $rad$, $point$)}
	\end{algorithm}
		
\end{frame}

% JJ
\begin{frame}
	\frametitle{Searching the tree}
	
	\texttt{search501} reads the 501-st data file and loops through the points contained within (as well as the three given radii), calling \texttt{searchTree\_serial} for each
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
%		\footnotesize
		\begin{algorithmic}[1]
			\STATE 
		\end{algorithmic}
		\caption{\texttt{search501}($tree$, $path$, $\cdots$)}
	\end{algorithm}
		
\end{frame}


\subsection{Parallel sorting}


\subsubsection{Changes}

\begin{frame}
	\frametitle{Parallel sorting}
	
	We had to make several significant alterations to our \texttt{parallelSort} program in order to integrate it into our KD tree project
	
	\vspace{10pt}
	
	\begin{block}{Changes:}
		\begin{itemize}
			\item Make rank 0 do work
			\item Use specified communicator
			\item Conversion to function
			\item better \texttt{adaptBins}
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}
	\frametitle{Parallel sorting}
	
	\begin{block}{Making rank 0 do work:}
		\begin{itemize}
			\item Initially, rank 0 was just a master node which coordinated the other worker nodes
			\item This technique is very inefficient for parallel ORB since it requires us to switch to serial mode sooner
			\item The solution involved 1) cleverly altering a large number of if statements in the code and 2) changing how certain types of sends/recvs were handled
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}
	\frametitle{Parallel sorting}
	
	\begin{block}{Using a specified communicator:}
		\begin{itemize}
			\item Initially, \texttt{parallelSort} and all of its associated functions used MPI\_COMM\_WORLD (hard-coded)
			\item To use a specified communicator $comm$, it must be passed as an argument into any function that uses it
			\item This required a simple but tedious process of editing
		\end{itemize}
	\end{block}
\end{frame}

\begin{frame}
	\frametitle{Building the tree}
	
	Here is how \texttt{parallelSort} is structured now that it is a function
	
	\vspace{10pt}
	
	\begin{algorithm}[H]
%		\footnotesize
		\begin{algorithmic}[1]
			\STATE Locally sort $data$ on each compute node using a qsort
			\STATE Determine the global min/max of the $sortDim$
			\STATE Create linearly spaced bin edges over range on rank 0 and Bcast
			\STATE Bin the $data$ on each compute node and accumulate on rank 0
			\STATE Calculate $uniformity$
			\WHILE{ $uniformity < threshold$ \&\& $iterations < M$ }
				\STATE Adapt the bin edges on rank 0 and Bcast
				\STATE Bin the $data$ on each compute node and accumulate on rank 0
				\STATE Calculate $uniformity$
			\ENDWHILE
			\STATE Swap $data$ between compute nodes and do data cleanup
		\end{algorithmic}
		\caption{\texttt{parallelSort}($data$, $rows$, $myRank$, $sortDim$, $comm, \cdots$)}
	\end{algorithm}
		
\end{frame}


\subsubsection{\texttt{adaptBins}}

\begin{frame}
	\frametitle{Parallel sorting}
	
	We also wished to modify our original \texttt{adaptBins} function
	
%	\vspace{5pt}
	
	\begin{block}{Old \texttt{adaptBins}:}
		\begin{itemize}
			\item Local method
			\item Based on the normalized gradient of the bin counts
			\item Scaled so that bin edges remain properly ordered
			\item Scale decreases over time to avoid oscillations
			\item \textbf{Pros:} able to handle nonlinearities in distribution, good at fine-tuning
			\item \textbf{Cons:} edges from from dense regions are slow to converge, slower with more nodes
		\end{itemize}
	\end{block}
	
	\vspace{-10pt}
	
	\begin{equation}
		\begin{split}
			\Delta C & = 2.0 ( C^{m}_{i+1} - C^{m}_i ) / ( C^{m}_{i+1} + C^{m}_i ) \\
			\Delta E & = E^m_{i+1} - E^m_i \\
			S(m) & = 1 - (1 - 0.1) (1 - \textrm{exp}(-0.03 m) \\
			E^{m+1}_i & = E^m_i + 0.475 \big( S(m) \Delta C \Delta E \big)
		\end{split}
	\end{equation}
	
\end{frame}

\begin{frame}
	\frametitle{Parallel sorting}
	
	We also wished to modify our original \texttt{adaptBins} function
	
%	\vspace{5pt}
	
	\begin{block}{New \texttt{adaptBins}:}
		\begin{itemize}
			\item Global method
			\item Based on the integrated, linearly interpolated, cumulative distribution
			\item Bin edges placed where linear interpolation would assume uniformity
			\item \textbf{Pros:} fast initial convergence in approximately linear regions, same speed with more nodes
			\item \textbf{Cons:} can oscillate near dense regions
		\end{itemize}
	\end{block}
	
	\vspace{-5pt}
	
	\begin{equation}
		\hat C(x) = \hat C(E^m_{i'}) + C^m_{i'} \dfrac{x - E^m_{i'}}{E^m_{{i'}+1} - E^m_{i'}} = (i+1) \dfrac{D}{N}
	\end{equation}
	
	\begin{equation}
		E^{m+1}_i = E^m_{i'} + \Big( (i+1) \dfrac{D}{N} - C(E^m_{i'}) \Big) (E^m_{{i'}+1} - E^m_{i'}) / C^m_{i'}
	\end{equation}
	
\end{frame}

\begin{frame}
	\frametitle{Parallel sorting}
	
	ALTERNATE
	
	Since both methods' pros and cons are disjoint, alternating between them gives a method which can outperform either individually
	
	\begin{block}{Demos:}

		\begin{itemize}
			\item thin dense distribution at boundary, nBins = 2, 3, 10
			\item wide distribution in center, nBins = 2, 3, 10
			\item 
		\end{itemize}

	\end{block}
	
	
\end{frame}




%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Validation}

\begin{frame}	
	\begin{Huge}
		\begin{center}
			Validation
		\end{center}
	\end{Huge}
\end{frame}

\subsection{MATLAB visualizations}

\begin{frame}	
	\frametitle{Validation}
	
	\begin{block}{MATLAB Demos:}
		\begin{itemize}
			\item 2D animation of MATLAB prototype
			\item 3D visualization at the end of the parallel phase of the C++ implementation
		\end{itemize}
	\end{block}
	
\end{frame}

\begin{frame}	
	\frametitle{Validation}
	\vspace{-8pt}
	\begin{figure}
		\centering
		\includegraphics[width=0.65\textwidth]{images/squares.png}
		\vspace{-15pt}
		\caption{Example of $k$-d tree partitions}
	\end{figure}
	
\end{frame}


\subsection{Other tests}

\begin{frame}	
	\frametitle{Validation}
	
	\begin{block}{Other validation methods:}
		\begin{itemize}
			\item Set search sphere center on a data point, use tiny radius, find 1 point
			\item Set an arbitrary search sphere point, increase radius, points found increases monotonically
			\item Consistent results for different numbers of nodes
			\item \texttt{dumpTree} writes each compute node's tree to a file for analysis
		\end{itemize}
	\end{block}
	
\end{frame}




%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Results}

\begin{frame}	
	\begin{Huge}
		\begin{center}
			Results
		\end{center}
	\end{Huge}
\end{frame}


%%%%%%%%%%%%%
%%% NEW SECTION %%%
%%%%%%%%%%%%%
\section{Conclusions}

\begin{frame}	
	\begin{Huge}
		\begin{center}
			Conclusions
		\end{center}
	\end{Huge}
\end{frame}

\subsection{Challenges}

\begin{frame}	
	\frametitle{Challenges}
	
	\begin{alertblock}{Challenges:}
		\begin{itemize}
			\item \texttt{parallelSort} conversions
			\item memory leaks
			\item \texttt{malloc} when you should \texttt{realloc}
			\item multiple communicators (comm)
			\item \texttt{adaptBins} convergence problems
			\item debug print statement clutter
			\item array out of bounds issues
			\item inconsistent usage pointer-to-pointer calls for *data[] and *rows (due to \texttt{swapArrayParts})
			\item no planning for function arguments and return values (constant editing of h-files)
			\item testing was difficult due to cluster overloading and hardware errors
		\end{itemize}
	\end{alertblock}

\end{frame}

\begin{frame}	
	\frametitle{Challenges}
	
	\begin{alertblock}{Obnoxious personality quirks and idiotic coding habits:}
		% so put your complaints about each other here LOL (all that sand tho)
		\begin{itemize}
			\setlength\itemsep{0.5pt}
			\item Graham: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item Fixates on dumb, small things; slows team progress (can't see the forest for the trees)
				\end{itemize}
			\item James: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item 
				\end{itemize}
			\item JJ: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item Insistent usage of Visual Studio replaces neatly arranged tabs with ugly, inconsistent spaces (also doesn't update Makefile)
					\item SO MUCH debug \texttt{cout} clutter
				\end{itemize}
		\end{itemize}
	\end{alertblock}

\end{frame}

\subsection{Successes}

\begin{frame}	
	\frametitle{Successes}
	
	\begin{exampleblock}{Successes:}
		\begin{itemize}
			\item few merge conflicts and fast debugging through extreme coding and Git branches
			\item visualizing output through MATLAB
			\item efficient delegation of tasks
		\end{itemize}
	\end{exampleblock}

\end{frame}

\begin{frame}	
	\frametitle{Successes}
	
	\begin{exampleblock}{Helpful personality quirks and proper coding habits:}
		% so put your complaints about each other here LOL (all that sand tho)
		\begin{itemize}
			\setlength\itemsep{0.5pt}
			\item Graham: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item I can do math
				\end{itemize}
			\item James: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item Engineering mindset provides more efficient solutions to problems
				\end{itemize}
			\item JJ: \\
				\begin{itemize}
					\setlength\itemsep{0.5pt}
					\item C++ guru
				\end{itemize}
		\end{itemize}
	\end{exampleblock}

\end{frame}

\subsection{Future Work}

\begin{frame}	
	\frametitle{Future Work}
	
	\begin{block}{Future work:}
		\begin{itemize}
			\item cloud computing
			\item use of coding techniques for personal research
		\end{itemize}
	\end{block}
	
\end{frame}




 
\end{document}












